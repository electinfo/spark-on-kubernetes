# Spark Connect Server - Long-running Spark service with gRPC endpoint
#
# Provides a persistent Spark session that clients can connect to via Spark Connect.
# Clients use: SparkSession.builder.remote("sc://spark-connect.spark.svc:15002").getOrCreate()
#
# Deploy:  kubectl apply -k ops/app-spark-connect/base/
# Check:   kubectl get pods -n spark -l app=spark-connect-server
# Logs:    kubectl logs -n spark -l app=spark-connect-server
# Delete:  kubectl delete -k ops/app-spark-connect/base/
#
# Connect from magnum:
#   export SPARK_REMOTE="sc://spark-connect.spark.svc:15002"
#   pyspark
#
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-connect-server
  namespace: spark
  labels:
    app: spark-connect-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-connect-server
  template:
    metadata:
      labels:
        app: spark-connect-server
    spec:
      serviceAccountName: spark-operator-spark
      nodeSelector:
        kubernetes.io/hostname: cyberpower
      containers:
        - name: spark-connect
          image: localhost:32000/electinfo/spark-connect-server:latest
          imagePullPolicy: Always
          command:
            - /bin/bash
            - -c
            - |
              # Create Ivy cache directory (spark user home is /nonexistent in /etc/passwd)
              mkdir -p /nonexistent/.ivy2.5.2/cache /nonexistent/.ivy2.5.2/jars

              # Start Spark Connect server using properties file
              exec /opt/spark/sbin/start-connect-server.sh \
                --master k8s://https://kubernetes.default.svc:443 \
                --deploy-mode client \
                --name spark-connect-server \
                --properties-file /opt/spark/conf/spark-defaults.conf \
                --conf spark.driver.host=$POD_IP
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: SPARK_NO_DAEMONIZE
              value: "true"
          ports:
            - name: spark-connect
              containerPort: 15002
              protocol: TCP
            - name: spark-ui
              containerPort: 4040
              protocol: TCP
            - name: driver-rpc
              containerPort: 7078
              protocol: TCP
            - name: block-manager
              containerPort: 7079
              protocol: TCP
          resources:
            requests:
              memory: "8Gi"
              cpu: "4"
            limits:
              memory: "16Gi"
              cpu: "8"
          volumeMounts:
            - name: spark-conf
              mountPath: /opt/spark/conf
            - name: ivy-cache
              mountPath: /nonexistent
            - name: spark-local
              mountPath: /tmp/spark-local
      volumes:
        - name: spark-conf
          configMap:
            name: spark-connect-config
        - name: ivy-cache
          emptyDir: {}
        - name: spark-local
          emptyDir: {}

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-connect-config
  namespace: spark
data:
  spark-defaults.conf: |
    # Spark Connect Server configuration
    # All settings loaded via --properties-file

    # Prometheus metrics
    spark.ui.prometheus.enabled                          true
    spark.metrics.conf                                   /opt/spark/conf/metrics.properties

    # Maven packages
    spark.jars.packages                                  org.apache.hadoop:hadoop-aws:3.4.2,software.amazon.awssdk:bundle:2.29.6,org.neo4j:neo4j-connector-apache-spark_2.13:5.3.10_for_spark_3,org.postgresql:postgresql:42.7.1,io.graphframes:graphframes-spark4_2.13:0.10.0
    spark.jars.ivy                                       /nonexistent/.ivy2.5.2

    # Kubernetes settings
    spark.kubernetes.container.image                     localhost:32000/electinfo/spark-executor:latest
    spark.kubernetes.namespace                           spark
    spark.kubernetes.authenticate.driver.serviceAccountName spark-operator-spark
    spark.kubernetes.executor.podTemplateFile            /opt/spark/conf/executor-pod-template.yaml
    spark.kubernetes.file.upload.path                    /tmp/spark-uploads

    # Executor settings
    spark.executor.instances                             5
    spark.executor.cores                                 8
    spark.executor.memory                                48g
    spark.driver.memory                                  8g

    # Dynamic allocation (disabled for stable executor count)
    spark.dynamicAllocation.enabled                      false
    spark.dynamicAllocation.minExecutors                 1
    spark.dynamicAllocation.maxExecutors                 1
    spark.dynamicAllocation.executorIdleTimeout          120s

    # Hive metastore
    spark.sql.catalogImplementation                      hive
    spark.sql.hive.metastore.version                     4.1.0
    spark.sql.hive.metastore.jars                        maven
    spark.hadoop.hive.metastore.uris                     thrift://app-hive.electinfo.svc.cluster.local:9083
    spark.sql.warehouse.dir                              s3a://electinfo/hive-warehouse

    # Event logging
    spark.eventLog.enabled                               true
    spark.eventLog.dir                                   s3a://spark-history/

    # S3A configuration for MinIO
    spark.hadoop.fs.s3a.endpoint                         http://10.10.0.10:9000
    spark.hadoop.fs.s3a.path.style.access                true
    spark.hadoop.fs.s3a.impl                             org.apache.hadoop.fs.s3a.S3AFileSystem
    spark.hadoop.fs.s3a.connection.ssl.enabled           false
    spark.hadoop.fs.s3a.access.key                       electinfo
    spark.hadoop.fs.s3a.secret.key                       electinfo123
    spark.hadoop.fs.s3a.aws.credentials.provider         org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
    spark.hadoop.fs.s3a.change.detection.mode            none
    spark.hadoop.fs.s3a.buffer.dir                       /tmp/spark-local

  metrics.properties: |
    # Enable Prometheus metrics export
    *.sink.prometheusServlet.class=org.apache.spark.metrics.sink.PrometheusServlet
    *.sink.prometheusServlet.path=/metrics/prometheus
    master.source.jvm.class=org.apache.spark.metrics.source.JvmSource
    worker.source.jvm.class=org.apache.spark.metrics.source.JvmSource
    driver.source.jvm.class=org.apache.spark.metrics.source.JvmSource
    executor.source.jvm.class=org.apache.spark.metrics.source.JvmSource

  executor-pod-template.yaml: |
    apiVersion: v1
    kind: Pod
    spec:
      terminationGracePeriodSeconds: 30
      containers:
        - name: spark-kubernetes-executor
          volumeMounts:
            - name: spark-local
              mountPath: /tmp/spark-local
            - name: spark-checkpoints
              mountPath: /mnt/spark-checkpoints
      volumes:
        - name: spark-local
          emptyDir:
            sizeLimit: 20Gi
        - name: spark-checkpoints
          nfs:
            server: 10.10.0.10
            path: /volume1/spark-checkpoints
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  spark-app-name: spark-connect-server
              topologyKey: kubernetes.io/hostname

---
# Service to expose Spark Connect endpoint
apiVersion: v1
kind: Service
metadata:
  name: spark-connect
  namespace: spark
  labels:
    app: spark-connect-server
spec:
  type: NodePort
  selector:
    app: spark-connect-server
  ports:
    - name: spark-connect
      port: 15002
      targetPort: 15002
      nodePort: 31500
      protocol: TCP
    - name: spark-ui
      port: 4040
      targetPort: 4040
      nodePort: 30404
      protocol: TCP